#include<iostream>
#include<vector>
#include<string>
using namespace std;

/*
布隆过滤器
我们在使用新闻客户端看新闻时，它会给我们不停地推荐新的内容，它每次推荐时要去重，去掉
那些已经看过的内容。问题来了，新闻客户端推荐系统如何实现推送去重的？ 用服务器记录了用
户看过的所有历史记录，当推荐系统推荐新闻时会从每个用户的历史记录里进行筛选，过滤掉那
些已经存在的记录。 如何快速查找呢？
1. 用哈希表存储用户记录，缺点：浪费空间
2. 用位图存储用户记录，缺点：位图一般只能处理整形，如果内容编号是字符串，就无法处理了。
3. 将哈希与位图结合，即布隆过滤器, 将字符串通过字符串哈希算法，转成整形
	优点：节省空间
	问题：存在哈希冲突，哈希冲突解决不了，只能缓解问题
	缓解哈希冲突方法：一个值映射到多个位置，降低冲突的概率，类型不一定是字符串
	提出这种方法的人 叫 布隆


布隆过滤器:
优点:节省空间，高效，可以标记存储任意类型
缺点:存在误判，不支持删除
*/

namespace cr
{
	class bitset
	{
	public:
		bitset(size_t N)
		{
			_bits.resize(N / 32 + 1, 0);//一个整型32位，要除以32，+1是因为除数只保留整数
			_num = 0;
		}

		void set(size_t x)
		{
			size_t index = x / 32;//x映射的位在第几个整形里
			size_t pos = x % 32;//x映射的位在这个整形的第几位里

			_bits[index] |= (1 << pos);//第pos位 置1
			++_num;
		}

		void reset(size_t x)
		{
			size_t index = x / 32;//x映射的位在第几个整形里
			size_t pos = x % 32;//x映射的位在这个整形的第几位里

			_bits[index] &= ~(1 << pos);//第pos位置0
			--_num;
		}

		//判断数据x是否存在
		bool test(size_t x)
		{
			size_t index = x / 32;//x映射的位在第几个整形里
			size_t pos = x % 32;//x映射的位在这个整形的第几位里

			return _bits[index] & (1 << pos);//判断第pos位 是否为1			
		}
	private:
		//int* _bits;
		std::vector<int> _bits;	//使用vector就直接用vector的内置函数
		size_t _num;//映射存储数据的数量		
	};

	//BKDR Hash 
	struct HashStr1
	{
		size_t operator()(const string& str)
		{
			int i = 0;
			size_t hash = 0;
			for (i = 0; i < str.length(); ++i)
			{
				hash *= 131;
				hash += str[i];
			}
			return hash;
		}
	};

	//AP Hash 
	struct HashStr2
	{
		size_t operator()(const string& s)
		{
			size_t hash = 0;
			for (long i = 0; i < s.size(); i++)
			{
				if ((i & 1) == 0)
				{
					hash ^= ((hash << 7) ^ s[i] ^ (hash >> 3));
				}
				else
				{
					hash ^= (~((hash << 11) ^ s[i] ^ (hash >> 5)));
				}
			}
			return hash;
		}
	};

	//DJB Hash 
	struct HashStr3
	{
		size_t operator()(const string& s)
		{
			size_t hash = 5381;
			for (auto ch : s)
			{
				hash += (hash << 5) + ch;
			}
			return hash;
		}
	};

	//通过多个仿函数，将同一个K映射到不同的位置上,用的最多的是字符串，所以默认类型为字符串
	template<class K = string,class Hash1= HashStr1,class Hash2= HashStr2,class Hash3= HashStr3>
	class bloomfilter
	{
	public:
		/*
		选择哈希函数个数和布隆过滤器长度
		过小的布隆过滤器很快所有的 bit 位均为 1，那么查询任何值都会返回“可能存在”，起不到过滤的目的了。
		布隆过滤器的长度会直接影响误报率，布隆过滤器越长其误报率越小。

		另外，哈希函数的个数也需要权衡，
		个数越多则布隆过滤器 bit 位置位 1 的速度越快，且布隆过滤器的效率越低；
		但是如果太少的话，那我们的误报率会变高。
		
		如何选择适合业务的 k 和 m 值
		k = m/n * ln2
		k 为哈希函数个数，m 为布隆过滤器长度，n 为插入的元素个数，p 为误报率
		*/
		//这里实现的哈希函数个数k =3；则m=4.3*n  这里选的5
		bloomfilter(size_t num):_bs(5*num),_N(5*num)
		{}

		void set(const K& key)
		{
			//Hash1()是一个匿名对象
			size_t index1 = Hash1()(key) % _N;
			size_t index2 = Hash2()(key) % _N;
			size_t index3 = Hash3()(key) % _N;

			cout << index1 << endl;
			cout << index2 << endl;
			cout << index3 << endl << endl;

			_bs.set(index1);
			_bs.set(index2);
			_bs.set(index3);
		}

		void reset(size_t x)
		{
			//不可以直接置位0，因为一个值有多个映射位置
			// 不支持删除，删除可能会影响其他值。
		}

		bool test(const K& key)
		{
			size_t index1 = Hash1()(key) % _N;
			if (_bs.test(index1) == false)
				return false;
			size_t index2 = Hash2()(key) % _N;
			if (_bs.test(index2) == false)
				return false;
			size_t index3 = Hash3()(key) % _N;
			if (_bs.test(index3) == false)
				return false;

			return true;//这里也不是真正的存在，存在误判

			//判断在，不准确，存在误判
			//判断不在，是准确的
		}
	private:
		bitset _bs;
		size_t _N;
	};
}

void test_bloomfilter()
{
	//cr::bloomfilter<> bf(100);//有缺省值，可以省略类型，但不可省略<>
	cr::bloomfilter<string> bf(100);
	bf.set("abcd");
	bf.set("acbd");
	bf.set("aadd");

	cout << bf.test("abcd");
	cout << bf.test("acbd");
	cout << bf.test("aadd");
}
/*
面试题：

1.给定100亿个整数，设计算法找到只出现一次的整数?
分析:100亿个整数大概占用40G
1G=2^30 Byte
数据出现的次数分为三种:出现0次、出现1次、出现2次及以上
位图的改进来解决问题，两个位表示一个整数:00  01  10
可以用一个位图的两位表示一个数，也可以用两个位图的各一位表示一位数，推荐两个位图

2.给两个文件，分别有100亿个整数，我们只有1G内存，如何找到两个文件交集?
方案1:将其中一个文件1的整数映射到一个位图中，读取另外一个文件2中的整数，判断在不在位图，在就是交集。 消耗512M内存
方案2:将文件1的整数映射到位图1中，将文件2的整数映射到位图2中，然后将两个位图中的数按位与。与之后为1的位就是交集。消耗内存1G。

3.位图应用变形:1个文件有100亿个int，16内存，设计算法找到出现次数不超过2次的所有整数
本题跟上面的第1题思路是一样的
本题找的不超过2次的，也就是要找出现1次和2次的
本题还是用两个位表示一个数，分为出现0次的00表示，出现1次的01表示，出现2次的10表示，出现3次及3次以上的用11表示


布隆过滤器:

1.给两个文件，分别有100亿个query，我们只有1G内存，如何找到两个文件交集?分别给出精确算法和近似算法

分析:(query一般是sql查询语句或者网络请求的url等，一般是一个字符串)
100亿个query占用多少空间呢?假设平均一个query30-60byte，100亿个query大约占用300-600G
方案一:将文件1中的query映射到一个布隆过滤器，读取文件2中的query判断在不在布隆过滤器中，在就是交集。
方案一缺陷:交集中有些数不准确，还是有些交集的数据漏掉了?
	布隆过滤器判断在是不准确的,判断不在是准确的
	所以交集中有些数不准确，没有数据漏掉

方案一不准确，下面是方案二
分析思路:这两个文件都非常大，大概在300-600G之间，也没有合适的数据结构能直接精确的找出交集。
方案二：文件很大不能都放到内存中，那么我们可以把文件切分多个小文件，小文件数据加载到内存中。
切分成多少份:	一般切出来一个小文件的大小能放进内存就可以。
这里一个文件300-600G，切1000份，一个小文件300-600M，这里有1G内存，可以。

再分析:如果是平均切分，那么文件A的小文件A0可以放到内存中存储到一个set中，那么文件B的B0-B999小文件中的数据都得跟A0比较
以此类推，A1放到内存中后，也得跟B0-B999小文件中的数据比较。
可以看到这里的优势就是比较的过程放到内存中，但是这里要不断的互相比较。
解决的优势:
		1、部分数据放到内存中 
		2、不是暴力比较，因为Ax的小文件的数据放在set中，比较效率还是能高很多。

再进行优化：上面比较次数很多，小文件Ax与Bx每两个都要进行比较。
不再平均切分，而是进行哈希切分: i=hashstr(query)%1000，1000是指切成1000份
i是多少，query就进入第Ai/Bi的小文件中，文件A/文件B都是这样处理
同一个hashstr，文件A和文件B中相同的query一定进入编号相同的Ai和Bi小文件，
所以只需要编号相同找交集就可以，即A0与B0比较，A1与B1比较……

2.如何扩展BloomFilter使得它支持删除元素的操作

每个位标记成计数器
那么到底用几个位来表示计数器呢?给的位如果少了，如果多个值映射一个位置就到导致计数器溢出。
比如1个byte最多计数到256，假设有260值都映射一个位置，就出问题了。
但是如果使用的更多的位映射一个位置，那么空间消耗就大了，不要忘了布隆过滤器的特点就是节省空间。

1、给一个超过100G大小的1og file(日志)，1og中存着IP地址，设计算法找到 出现次数最多 的IP地址?
与上题条件相同，如何找到top K的IP?如何直接用Linux系统命令实现?
分析:首先这里要做的是统计次数，统计次数我们一般用kv模型的map解决，但是这里的问题是有100G数据，放不到内存中。
	也不能进行平均切分成小文件，平均切分的话在统计次数时效率很低，因为相同的IP会被切分到不同小文件中，在统计一个IP次数时需要把所有小文件遍历
	所以使用哈希切分，先创建1000个小文件A0-A999，读取IP计算出i=hashstr(IP)%1000.
	i是多少，IP就进入对应编号的Ai小文件。这样相同IP一定进入了同一个小文件。
map<string,int〉countMap,读取Ai中的人IP统计出次数，一个读完了clear，再读另一个。
使用一个pair<string,int〉max记录出现次数最多的IP就可以求出。、
如果要找top K，那么用一个堆来搞定就可以。

*/

/*
一致性哈希算法:

一般情况下现在一台电脑内存8-16-32G，硬盘是500-1024G
假设我们要存储每个人的微信号和他的朋友圈信息，并且要方便快速查找。<微信号，朋友圈>
我们现在真需要考虑是服务器存储数据的问题，因为微信有10亿用户，假设平均一个用户的信息是100M,
那么大概需要 (10亿*100M，大约100000000G， 10WT)，也就是说差不多需要10W台服务器来存储
多机存储，还需要满足增删查改数据的需求
分析一下:用户laoganma发朋友圈了，插入到哪台机器，浏览和删朋友圈去哪台机器查找?
用户的朋友圈信息存储和机器建立一个映射关系
比如laoganma的信息存几号机器呢? i = hashstr(laoganma) % 10W
i是多少，laoganma的信息就存到第i号机器
(注意实际中可以需要用一台额外机器存储机器编号和IP的映射关系
这样我算出是i号机器，就可以找到他的IP，就可以找访问服务器了)

上面方案的缺陷:假设随着大家发朋友圈越来越多，或者用户量继续增长，10W台不够了，我们需要增加机器数量到15W台。
那么之前10W台机器上的数据映射关系就不对了，就需要重新计算位置迁移数据
这时候就需要用到一致性哈希了
一致性哈希：
用户的朋友圈信息存储和机器建立一个映射关系
比如laoganma的信息存几号机器呢? i = hashstr(laoganma) % 2^32
i是多少，laoganma的信息就存到第i号机器
注意这里的大小也可以是其他值，不过要大一些就可以，比如50亿、100亿

0到2~32-1中的一段范围的值去映射一台服务器，整个段的范围就映射这10W台机器
如果你要增加5W台机器，那么不需要所有数据迁移，只需要迁移部分负载重的的机器上数据
比如:	计算10000-20000范围映射3号服务器，现在增加机器了，
		就可以让10000-15000范围映射新增机器X，迁移3号服务器中映射在10000-15000范围的数据到新机器X即可

总结:
一致性哈希就是给一个特别大的除数，那么增加机器也不需要整个重新计算迁移。
他是一段范围值映射到一个一台机器<x1-x2,ip〉，(范围值x1至x2的值 映射到一个IP中)
那么增加机器后，只需要改变映射范围即可，然后迁移极小部分的数据。
*/
int main()
{
	test_bloomfilter();
	return 0;
}
